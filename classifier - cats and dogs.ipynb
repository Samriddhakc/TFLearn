{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# classifier: cats vs. dogs\n",
    "# dataset: https://www.kaggle.com/c/dogs-vs-cats\n",
    "# Author: Ying Meng\n",
    "\n",
    "# ---------------------\n",
    "# import required packages\n",
    "# ---------------------\n",
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from random import shuffle\n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import train_test_split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------\n",
    "# define constants\n",
    "# ---------------------\n",
    "TRAIN_DIR = '/home/rabina7/Downloads/dogs-vs-cats/train'\n",
    "TEST_DIR = '/home/rabina7/Downloads/dogs-vs-cats/test1'\n",
    "IMG_SIZE = 50 # resize all images to the same size\n",
    "LR = 1e-3 # learning rate: 0.001\n",
    "\n",
    "# model name, for model loading and saving\n",
    "MODEL_NAME = 'catsvsdogs-{}-{}.model'.format(LR, '6conv-basic')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# output of our model is an array consists 2 elements: [catniss, dogniss]\n",
    "# each element represents the probability of being each animal.\n",
    "# e.g., [1, 0] means this image is 100% a cat image and 0% a dog image.\n",
    "# So, the final label of the image is cat.\n",
    "\n",
    "categories = ['cat', 'dog']\n",
    "\n",
    "def img_label(img):\n",
    "    # get the true label of the image\n",
    "    # images in training set are named in form of <animal>.xx.jpg, xx are numbers.\n",
    "    text_label = img.split('.')[-3]\n",
    "    \n",
    "    if text_label == categories[0]:\n",
    "        return [1, 0]\n",
    "    elif text_label == categories[1]:\n",
    "        return [0, 1]\n",
    "    else:\n",
    "        raise ValueError('The image does not belong to any category! ' + text_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------\n",
    "# process training data\n",
    "# ---------------------\n",
    "def process_train_data():\n",
    "    training_data = []\n",
    "    for img in tqdm(os.listdir(TRAIN_DIR)):\n",
    "        # full path of the image\n",
    "        img_full_path = os.path.join(TRAIN_DIR, img)\n",
    "        # true label of the image\n",
    "        true_label = img_label(img)\n",
    "        # load the image\n",
    "        img = cv2.imread(img_full_path, cv2.IMREAD_GRAYSCALE)\n",
    "        # resize the image\n",
    "        img = cv2.resize(img, (IMG_SIZE, IMG_SIZE))\n",
    "        # add new training data, in form of\n",
    "        # (img, label)\n",
    "        training_data.append([np.array(img), np.array(true_label)])\n",
    "    # shuffle the dataset\n",
    "    shuffle(training_data)\n",
    "    # save the dataset so that next time we can load it directly\n",
    "    np.save('trainset-{}.npy'.format(IMG_SIZE), training_data)\n",
    "    \n",
    "    return training_data       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------\n",
    "# process testing data\n",
    "# ---------------------\n",
    "def process_test_data():\n",
    "    testing_data = []\n",
    "    for img in tqdm(os.listdir(TEST_DIR)):\n",
    "        # full path of the image\n",
    "        img_full_path = os.path.join(TEST_DIR, img)\n",
    "        img_idx = img.split('.')[0]\n",
    "        # load the image\n",
    "        img = cv2.imread(img_full_path, cv2.IMREAD_GRAYSCALE)\n",
    "        # resize the image\n",
    "        img = cv2.resize(img, (IMG_SIZE, IMG_SIZE))\n",
    "        # add new testing data, in form of\n",
    "        # (img, img_idx)\n",
    "        testing_data.append([np.array(img), img_idx])\n",
    "        #calculating the testing\n",
    "        #simple loop that goes through all the \n",
    "        #API to predict the label and compare to the true label\n",
    "        #counter\n",
    "    shuffle(testing_data)\n",
    "    # save the dataset so that next time we can load it directly\n",
    "    np.save('testset-{}.npy'.format(IMG_SIZE), testing_data)\n",
    "    return testing_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------\n",
    "# load training data\n",
    "# ---------------------\n",
    "def load_train_data(load_exist):\n",
    "    trainset = None\n",
    "    if load_exist and os.path.exists('trainset-{}.npy'.format(IMG_SIZE)):\n",
    "        # if want to load an existing training set\n",
    "        trainset = np.load('trainset-{}.npy'.format(IMG_SIZE), allow_pickle = True)\n",
    "    else:\n",
    "        trainset = process_train_data()\n",
    "    return trainset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/rabina7/anaconda3/envs/opencv/lib/python2.7/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    }
   ],
   "source": [
    "# ---------------------\n",
    "# construct the cnn model for this project\n",
    "# ---------------------\n",
    "import tflearn\n",
    "\n",
    "from tflearn.layers.conv import conv_2d, max_pool_2d\n",
    "from tflearn.layers.core import input_data, dropout, fully_connected\n",
    "from tflearn.layers.estimator import regression\n",
    "\n",
    "def conv_net():\n",
    "    convnet = input_data(shape = [None, IMG_SIZE, IMG_SIZE, 1],\n",
    "                        name = 'input')\n",
    "    # conv_2d(incoming, nb_filter, filter_size, ..., activation)\n",
    "    convnet = conv_2d(convnet, 32, 5, activation = 'relu')\n",
    "    # max_pool_2d(incoming, kernel_size, ...)\n",
    "    convnet = max_pool_2d(convnet, 5)\n",
    "    \n",
    "    convnet = conv_2d(convnet, 64, 5, activation = 'relu')\n",
    "    convnet = max_pool_2d(convnet, 5)\n",
    "    \n",
    "    convnet = conv_2d(convnet, 32, 5, activation = 'relu')\n",
    "    convnet = max_pool_2d(convnet, 5)\n",
    "    \n",
    "    convnet = conv_2d(convnet, 64, 5, activation = 'relu')\n",
    "    convnet = max_pool_2d(convnet, 5)\n",
    "    \n",
    "    convnet = conv_2d(convnet, 32, 5, activation = 'relu')\n",
    "    convnet = max_pool_2d(convnet, 5)\n",
    "    \n",
    "    convnet = conv_2d(convnet, 64, 5, activation = 'relu')\n",
    "    convnet = max_pool_2d(convnet, 5)\n",
    "        \n",
    "    # fully_connected(incoming, n_units, activation, ...)\n",
    "    convnet = fully_connected(convnet, 1024, activation = 'relu')\n",
    "    # dropout(incoming, keep_prob)\n",
    "    convnet = dropout(convnet, 0.8)\n",
    "    \n",
    "    #standard recommendation for the Net arch\n",
    "    \n",
    "    convnet = fully_connected(convnet, 2, activation = 'softmax')\n",
    "    # regression(incoming, optimizer, learning_rate, loss, name, ...)\n",
    "    convnet = regression(convnet, optimizer = 'adam', learning_rate = LR,\n",
    "                             loss = 'categorical_crossentropy', name = 'targets')\n",
    "    \n",
    "    return convnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From build/bdist.linux-x86_64/egg/tflearn/initializations.py:119: __init__ (from tensorflow.python.ops.init_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.initializers.variance_scaling instead with distribution=uniform to get equivalent behavior.\n",
      "WARNING:tensorflow:From build/bdist.linux-x86_64/egg/tflearn/layers/core.py:239: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "WARNING:tensorflow:From build/bdist.linux-x86_64/egg/tflearn/objectives.py:66: calling reduce_sum_v1 (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n",
      "WARNING:tensorflow:From /home/rabina7/anaconda3/envs/opencv/lib/python2.7/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n"
     ]
    }
   ],
   "source": [
    "# ---------------------\n",
    "# define the model\n",
    "# ---------------------\n",
    "convnet = conv_net()\n",
    "model = tflearn.DNN(convnet, tensorboard_dir = 'log')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/rabina7/anaconda3/envs/opencv/lib/python2.7/site-packages/tensorflow/python/training/saver.py:1266: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use standard file APIs to check for files with this prefix.\n",
      "INFO:tensorflow:Restoring parameters from /home/rabina7/Downloads/catsvsdogs-0.001-6conv-basic.model\n",
      "('loaded existing model', 'catsvsdogs-0.001-6conv-basic.model')\n"
     ]
    }
   ],
   "source": [
    "# ---------------------\n",
    "# train the model\n",
    "# ---------------------\n",
    "\n",
    "# load model if exists\n",
    "if os.path.exists('{}.meta'.format(MODEL_NAME)):\n",
    "    model.load(MODEL_NAME)\n",
    "    print ('loaded existing model', MODEL_NAME)\n",
    "else:\n",
    "    # Loading the training data-set after pre-processing\n",
    "    # and splitting the testing data and validation data\n",
    "\n",
    "    train_data = load_train_data(True)\n",
    "    train = train_data[:-500]\n",
    "    validation = train_data[-500:]\n",
    "\n",
    "    # Setting up the features and lables\n",
    "    # x-Features & y-Labels\n",
    "    train_x = np.array([i[0] for i in train]).reshape(-1, IMG_SIZE, IMG_SIZE, 1)\n",
    "    train_y = [i[1] for i in train]\n",
    "    validation_x = np.array([i[0] for i in validation]).reshape(-1, IMG_SIZE, IMG_SIZE, 1)\n",
    "    validation_y = [i[1] for i in validation]\n",
    "    # Training the CNN model with the data-sets\n",
    "    model.fit({'input': train_x}, {'targets': train_y}, n_epoch = 15,\n",
    "                        validation_set = ({'input': validation_x}, {'targets': validation_y}),\n",
    "                        snapshot_step = 500, show_metric = True, run_id = MODEL_NAME)\n",
    "\n",
    "    # save the trained model\n",
    "    #model.save(MODEL_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the model acheives 90% accuracy, save it if not saved yet\n",
    "if not os.path.exists('{}.meta'.format(MODEL_NAME)):\n",
    "    model.save(MODEL_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------\n",
    "# load testing data\n",
    "# ---------------------\n",
    "def load_test_data(load_exist):\n",
    "    testset = None\n",
    "    if load_exist and os.path.exists('testset-{}.npy'.format(IMG_SIZE)):\n",
    "        # if want to load an existing testing set\n",
    "        testset = np.load('testset-{}.npy'.format(IMG_SIZE), allow_pickle = True)\n",
    "    else:\n",
    "        testset = process_test_data()\n",
    "    return testset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'module' object has no attribute 'dims'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-1222d57b926d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mtotal_test_samples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0melement\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtest_data\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0mpredicted_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdims\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0melement\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mpredicted_result\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0melement\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0mcounter\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'module' object has no attribute 'dims'"
     ]
    }
   ],
   "source": [
    "test_data = load_test_data(True)\n",
    "counter = 0\n",
    "total_test_samples = len(test_data)\n",
    "for element[0] in test_data:\n",
    "    predicted_result = model.predict(np.dims[element[0]])\n",
    "    if predicted_result == element[0]:\n",
    "        counter += 1\n",
    "    test_accuracy = counter / total_test_samples\n",
    "    print(\"The testing accuracy is {}.\".format(test_accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------\n",
    "# use trained model to predict given image\n",
    "# -------------------\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "test_data = load_test_data(True)\n",
    "fig = plt.figure(figsize = (10, 8))\n",
    "\n",
    "# test and plot 12 images\n",
    "for i, data in enumerate(test_data[:12]):\n",
    "    # cat: [1, 0]; dog: [0, 1]\n",
    "    img_data = data[0]\n",
    "    img_idx = data[1]\n",
    "    \n",
    "    sub_fig = fig.add_subplot(3, 4, i + 1)\n",
    "    \n",
    "    orig_data = img_data\n",
    "    # flatten image\n",
    "    data = img_data.reshape(IMG_SIZE, IMG_SIZE, 1)\n",
    "    \n",
    "    output = model.predict([data])[0]\n",
    "    \n",
    "    if np.argmax(output) == 1:\n",
    "        pred_label = 'dog'\n",
    "    else:\n",
    "        pred_label = 'cat'\n",
    "    \n",
    "    sub_fig.imshow(orig_data, cmap = 'gray')\n",
    "    \n",
    "    # predicted label and confidence\n",
    "    plt.title(pred_label + '; ' + str(np.max(output)))\n",
    "    sub_fig.get_xaxis().set_visible(False)\n",
    "    sub_fig.get_yaxis().set_visible(False)\n",
    "    \n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# dataset: https://www.kaggle.com/c/dogs-vs-cats\n",
    "\n",
    "# ---------------------\n",
    "# import required packages\n",
    "# ---------------------\n",
    "from __future__ import print_function\n",
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from random import shuffle\n",
    "from tqdm import tqdm\n",
    "import torchvision\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "import keras\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras import backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "x_train /= 255\n",
    "x_test /= 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28)\n",
      "(60000,)\n",
      "(10000, 28, 28)\n",
      "(10000,)\n"
     ]
    }
   ],
   "source": [
    "print(x_train.shape)\n",
    "print(y_train.shape)\n",
    "print(x_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Initialziation\n",
    "IMG_SIZE=28\n",
    "LR=0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Data reshaping\n",
    "y_train=y_train.reshape((60000,1))\n",
    "x_train=x_train.reshape((60000,28,28,1))\n",
    "# convert class vectors to binary class matrices\n",
    "y_train = keras.utils.to_categorical(y_train, 10)\n",
    "y_test = keras.utils.to_categorical(y_test, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0626 23:56:13.431845 140735728333696 deprecation_wrapper.py:119] From /usr/local/lib/python3.7/site-packages/tflearn/helpers/summarizer.py:9: The name tf.summary.merge is deprecated. Please use tf.compat.v1.summary.merge instead.\n",
      "\n",
      "W0626 23:56:13.433053 140735728333696 deprecation_wrapper.py:119] From /usr/local/lib/python3.7/site-packages/tflearn/helpers/trainer.py:25: The name tf.summary.FileWriter is deprecated. Please use tf.compat.v1.summary.FileWriter instead.\n",
      "\n",
      "W0626 23:56:13.439254 140735728333696 deprecation_wrapper.py:119] From /usr/local/lib/python3.7/site-packages/tflearn/collections.py:13: The name tf.GraphKeys is deprecated. Please use tf.compat.v1.GraphKeys instead.\n",
      "\n",
      "W0626 23:56:13.444903 140735728333696 deprecation_wrapper.py:119] From /usr/local/lib/python3.7/site-packages/tflearn/config.py:123: The name tf.get_collection is deprecated. Please use tf.compat.v1.get_collection instead.\n",
      "\n",
      "W0626 23:56:13.451669 140735728333696 deprecation_wrapper.py:119] From /usr/local/lib/python3.7/site-packages/tflearn/config.py:129: The name tf.add_to_collection is deprecated. Please use tf.compat.v1.add_to_collection instead.\n",
      "\n",
      "W0626 23:56:13.452522 140735728333696 deprecation_wrapper.py:119] From /usr/local/lib/python3.7/site-packages/tflearn/config.py:131: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# ---------------------\n",
    "# construct the cnn model for this project\n",
    "# ---------------------\n",
    "import tflearn\n",
    "import tensorflow as tf\n",
    "\n",
    "from tflearn.layers.conv import conv_2d, max_pool_2d\n",
    "from tflearn.layers.core import input_data, dropout, fully_connected, flatten\n",
    "from tflearn.layers.estimator import regression\n",
    "\n",
    "def conv_net():\n",
    "    convnet = input_data(shape = [None, IMG_SIZE, IMG_SIZE, 1],\n",
    "                        name = 'input')\n",
    "    print(convnet)\n",
    "    # conv_2d(incoming, nb_filter, filter_size, ..., activation)\n",
    "    convnet = conv_2d(convnet, 32, (3,3), activation = 'relu')\n",
    "    # max_pool_2d(incoming, kernel_size, ...)\n",
    "    convnet = max_pool_2d(convnet, 2)\n",
    "    \n",
    "\n",
    "    #flatten the layer\n",
    "    print(\"break_1\")\n",
    "    flatten = tflearn.flatten(convnet)\n",
    "    # fully_connected(incoming, n_units, activation, ...)\n",
    "    convnet = fully_connected(flatten, 5, activation = 'relu')\n",
    "    # dropout(incoming, keep_prob is drop_prob + keep+prob)\n",
    "\n",
    "    #standard recommendation for the Net arch    \n",
    "    logits = fully_connected(convnet, 10, activation = 'softmax')\n",
    "    #convnet = dropout(convnet, 0.8)\n",
    "    \n",
    "    #logits\n",
    "    #logits = tf.layers.dense(inputs=convnet, units=10)\n",
    "    \n",
    "    #regression(incoming, optimizer, learning_rate, loss, name, ...)\n",
    "    convnet = regression(logits, optimizer = 'adam', learning_rate = LR,\n",
    "                             loss = 'categorical_crossentropy', name = 'targets')\n",
    "\n",
    "    return convnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0626 23:56:13.461524 140735728333696 deprecation_wrapper.py:119] From /usr/local/lib/python3.7/site-packages/tflearn/layers/core.py:81: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "W0626 23:56:13.465680 140735728333696 deprecation.py:506] From /usr/local/lib/python3.7/site-packages/tflearn/initializations.py:119: calling UniformUnitScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "W0626 23:56:13.467242 140735728333696 deprecation.py:323] From /usr/local/lib/python3.7/site-packages/tensorflow/python/util/deprecation.py:507: UniformUnitScaling.__init__ (from tensorflow.python.ops.init_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.initializers.variance_scaling instead with distribution=uniform to get equivalent behavior.\n",
      "W0626 23:56:13.487558 140735728333696 deprecation_wrapper.py:119] From /usr/local/lib/python3.7/site-packages/tflearn/layers/conv.py:552: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n",
      "W0626 23:56:13.493695 140735728333696 deprecation.py:506] From /usr/local/lib/python3.7/site-packages/tflearn/initializations.py:174: calling TruncatedNormal.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "W0626 23:56:13.539422 140735728333696 deprecation_wrapper.py:119] From /usr/local/lib/python3.7/site-packages/tflearn/optimizers.py:238: The name tf.train.AdamOptimizer is deprecated. Please use tf.compat.v1.train.AdamOptimizer instead.\n",
      "\n",
      "W0626 23:56:13.551166 140735728333696 deprecation.py:506] From /usr/local/lib/python3.7/site-packages/tflearn/objectives.py:66: calling reduce_sum_v1 (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n",
      "W0626 23:56:13.646610 140735728333696 deprecation_wrapper.py:119] From /usr/local/lib/python3.7/site-packages/tflearn/summaries.py:46: The name tf.summary.scalar is deprecated. Please use tf.compat.v1.summary.scalar instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"input/X:0\", shape=(?, 28, 28, 1), dtype=float32)\n",
      "break_1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0626 23:56:13.705239 140735728333696 deprecation.py:323] From /usr/local/lib/python3.7/site-packages/tensorflow/python/ops/math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "W0626 23:56:13.947839 140735728333696 deprecation_wrapper.py:119] From /usr/local/lib/python3.7/site-packages/tflearn/helpers/trainer.py:134: The name tf.train.Saver is deprecated. Please use tf.compat.v1.train.Saver instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# ---------------------\n",
    "# define the model\n",
    "# ---------------------\n",
    "convnet = conv_net()\n",
    "model = tflearn.DNN(convnet, tensorboard_dir = 'log')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Step: 9379  | total loss: \u001b[1m\u001b[32m0.27395\u001b[0m\u001b[0m | time: 17.671s\n",
      "| Adam | epoch: 010 | loss: 0.27395 -- iter: 59968/60000\n",
      "Training Step: 9380  | total loss: \u001b[1m\u001b[32m0.25033\u001b[0m\u001b[0m | time: 17.688s\n",
      "| Adam | epoch: 010 | loss: 0.25033 -- iter: 60000/60000\n",
      "--\n"
     ]
    }
   ],
   "source": [
    "model.fit(x_train,y_train,n_epoch=10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "p=model.predict(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[7.9721685e-10, 1.6921947e-13, 9.9318043e-10, ..., 1.8597056e-11,\n",
       "        1.0196896e-04, 1.2178730e-03],\n",
       "       [9.9857759e-01, 1.1010650e-05, 4.1416576e-04, ..., 1.2678601e-08,\n",
       "        6.0156407e-04, 3.6364856e-06],\n",
       "       [4.8358723e-10, 2.8679817e-04, 1.7911589e-05, ..., 3.2650910e-03,\n",
       "        2.8881966e-04, 3.8544130e-02],\n",
       "       ...,\n",
       "       [4.3792874e-17, 7.5091223e-20, 8.8614379e-16, ..., 3.3064304e-16,\n",
       "        7.8296000e-07, 2.5055010e-04],\n",
       "       [4.2715464e-02, 8.5906824e-04, 3.7789539e-07, ..., 2.7400571e-09,\n",
       "        5.7125952e-05, 1.1411099e-05],\n",
       "       [8.4966337e-07, 1.1174529e-15, 7.2171497e-07, ..., 2.3052129e-15,\n",
       "        9.9999082e-01, 7.4881950e-06]], dtype=float32)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction=np.argmax(p,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "real_y_label=np.argmax(y_train,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_correct_count=0\n",
    "for i in range(len(prediction)):\n",
    "    if (prediction[i]==real_y_label[i]):\n",
    "        train_correct_count=train_correct_count+1;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Accuracy0.9784833333333334\n"
     ]
    }
   ],
   "source": [
    "print(\"train Accuracy\"+str(train_correct_count/x_train.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test Accuracy0.9583\n"
     ]
    }
   ],
   "source": [
    "test_correct_count=0;\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "y_test=y_test.reshape((10000,1))\n",
    "x_test=x_test.reshape((10000,28,28,1))\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "x_train /= 255\n",
    "x_test /= 255\n",
    "p_test=model.predict(x_test);\n",
    "prediction_test=np.argmax(p_test,axis=1)\n",
    "for i in range(len(prediction_test)):\n",
    "    if (prediction_test[i]==y_test[i]):\n",
    "        test_correct_count=test_correct_count+1;\n",
    "print(\"test Accuracy\"+str(test_correct_count/x_test.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([7, 2, 1, ..., 4, 5, 6])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[7],\n",
       "       [2],\n",
       "       [1],\n",
       "       ...,\n",
       "       [4],\n",
       "       [5],\n",
       "       [6]], dtype=uint8)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Hurray, ;)! "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
